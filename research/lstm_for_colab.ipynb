{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "lstm for colab",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Markfryazino/stanford_sentiment/blob/master/research/lstm_for_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHLQ6SdUclHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "3b27113e-42e4-48ce-b281-398f52d50ff6"
      },
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-02 14:50:23--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  21.4MB/s    in 6.7s    \n",
            "\n",
            "2020-07-02 14:50:30 (12.0 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5-Ov6HUcjnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "PATH = './'\n",
        "\n",
        "import os\n",
        "train_pos_names = os.listdir(PATH + 'aclImdb/train/pos')\n",
        "train_neg_names = os.listdir(PATH + 'aclImdb/train/neg')\n",
        "test_pos_names = os.listdir(PATH + 'aclImdb/test/pos')\n",
        "test_neg_names = os.listdir(PATH + 'aclImdb/test/neg')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTo-0er8cjng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = [int(s.split('_')[1].split('.')[0]) for s in train_pos_names] + \\\n",
        "          [int(s.split('_')[1].split('.')[0]) for s in train_neg_names]\n",
        "    \n",
        "y_test = [int(s.split('_')[1].split('.')[0]) for s in test_pos_names] + \\\n",
        "          [int(s.split('_')[1].split('.')[0]) for s in test_neg_names]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpAOubgzcjnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = []\n",
        "test = []\n",
        "\n",
        "for name in train_pos_names:\n",
        "    with open(PATH + 'aclImdb/train/pos/' + name) as f:\n",
        "        train.append(f.read())\n",
        "        \n",
        "for name in train_neg_names:\n",
        "    with open(PATH + 'aclImdb/train/neg/' + name) as f:\n",
        "        train.append(f.read())\n",
        "        \n",
        "for name in test_pos_names:\n",
        "    with open(PATH + 'aclImdb/test/pos/' + name) as f:\n",
        "        test.append(f.read())\n",
        "        \n",
        "for name in test_neg_names:\n",
        "    with open(PATH + 'aclImdb/test/neg/' + name) as f:\n",
        "        test.append(f.read())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0-YCozkcjnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val, y_train, y_val = train_test_split(train, y_train, shuffle=True, test_size=0.2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSege5go-wBJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4c957f6-a776-4cd6-b872-076006afb888"
      },
      "source": [
        "text = 'a b c c c d d a'\n",
        "from collections import Counter\n",
        "c = dict(Counter(text.split()))\n",
        "c = {key for key, val in c.items() if val >= 3}\n",
        "c"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'c'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lzJ9Knlcjnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from collections import Counter\n",
        "\n",
        "class Tokenizer:\n",
        "    def __init__(self, data, maxlen=1024, mincount=3):\n",
        "        self.maxlen = maxlen\n",
        "        self.mincount = mincount\n",
        "        text = ' '.join(data).lower()\n",
        "        text = re.sub(r'[^\\w\\s]','',text)\n",
        "        words = dict(Counter((text.split())))\n",
        "        words = {key for key, val in words.items() if val >= mincount}\n",
        "        self.num_tokens = len(words) + 4\n",
        "        self.w2i = {'<unk>': 0, '<BOS>': 1, '<EOS>': 2, '<pad>': 3}\n",
        "        self.i2w = ['<unk', '<BOS>', '<EOS>', '<pad>']\n",
        "        for w in words:\n",
        "            self.w2i[w] = len(self.i2w)\n",
        "            self.i2w.append(w)\n",
        "    \n",
        "    def tokenize(self, data):\n",
        "        output = []\n",
        "        for sent in data:\n",
        "            text = re.sub(r'[^\\w\\s]','',sent.lower())\n",
        "            output.append([1])\n",
        "            for w in text.split():\n",
        "                if w in self.w2i:\n",
        "                    output[-1].append(self.w2i[w])\n",
        "                else:\n",
        "                    output[-1].append(0)\n",
        "            output[-1].append(2)\n",
        "        return pad_sequences(output, maxlen=self.maxlen, value=3)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu8hx5eTcjnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok = Tokenizer(train, maxlen=512, mincount=3)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-eqGcIOcjn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tok = tok.tokenize(train)\n",
        "val_tok = tok.tokenize(val)\n",
        "test_tok = tok.tokenize(test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz4A08Lecjn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, num_tokens, emb_size=16, hid_size=64):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.lstm = nn.LSTM(emb_size, hid_size, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(2 * hid_size, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.type(torch.LongTensor).to(device)\n",
        "        emb = self.dropout(self.emb(x))\n",
        "        h, _ = self.lstm(emb)\n",
        "        estimate = self.fc(h[:, -1, :])\n",
        "        return torch.flatten(estimate)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-ErWUHCcjn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data, y):\n",
        "        self.data = data\n",
        "        self.y = y\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.y[idx]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_dwwU8EcjoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dset = TextDataset(train_tok, y_train)\n",
        "val_dset = TextDataset(val_tok, y_val)\n",
        "test_dset = TextDataset(test_tok, y_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmsHXM1vcjoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_dset, batch_size=16)\n",
        "val_loader = DataLoader(val_dset, batch_size=16)\n",
        "test_loader = DataLoader(test_dset, batch_size=16)\n",
        "\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEmA4ddpcjoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_quality(model, loader, classification=False):\n",
        "    model.eval()\n",
        "    \n",
        "    loss_acum = 0.\n",
        "    correct = total = 0\n",
        "    \n",
        "    for i_step, (x, y) in enumerate(loader):\n",
        "        x_gpu = x.to(device)\n",
        "        y_gpu = y.to(device)\n",
        "\n",
        "        if classification:\n",
        "            y_gpu = (y > 5).type(torch.FloatTensor).to(device)\n",
        "\n",
        "        pred = model(x_gpu)\n",
        "        loss_val = loss(pred, y_gpu)\n",
        "        loss_acum += loss_val\n",
        "        \n",
        "        pred_rounded = torch.round(pred)\n",
        "        correct += torch.sum(pred_rounded == y_gpu)\n",
        "        total += y.shape[0]\n",
        "        del x_gpu, y_gpu\n",
        "        \n",
        "    return loss_acum / (i_step + 1), float(correct) / total\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs, optimizer, loss, plato_scheduler=None, \n",
        "                scheduler=None, classification=False):\n",
        "    loss_history = []\n",
        "    acc_history = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        \n",
        "        loss_acum = 0.\n",
        "        correct = total = 0\n",
        "        \n",
        "        for i_step, (x, y) in enumerate(train_loader):\n",
        "            x_gpu = x.to(device)\n",
        "            y_gpu = y.to(device)\n",
        "\n",
        "            if classification:\n",
        "                y_gpu = (y > 5).type(torch.FloatTensor).to(device)\n",
        "\n",
        "            pred = model(x_gpu)\n",
        "            loss_val = loss(pred, y_gpu)\n",
        "            loss_acum += loss_val\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss_val.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            pred_rounded = torch.round(pred)\n",
        "            correct += torch.sum(pred_rounded == y_gpu)\n",
        "            total += y.shape[0]\n",
        "            del x_gpu, y_gpu\n",
        "            \n",
        "        train_acc = float(correct) / total\n",
        "        train_loss = loss_acum / (i_step + 1)\n",
        "        \n",
        "        val_loss, val_acc = compute_quality(model, val_loader, classification=classification)\n",
        "        loss_history.append(val_loss)\n",
        "        acc_history.append(val_acc)\n",
        "\n",
        "        if plato_scheduler != None:\n",
        "            scheduler.step(val_acc)\n",
        "        if scheduler != None:\n",
        "            scheduler.step()\n",
        "        \n",
        "        print(f'Epoch {epoch}\\nTrain loss: {train_loss}\\nTrain accuracy: {train_acc}')\n",
        "        print(f'Val loss: {val_loss}\\nVal accuracy: {val_acc}')\n",
        "    return loss_history, acc_history"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dtrl2Yc58wa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "bf603002-a1a6-4f19-aeb4-1b5e24396ad7"
      },
      "source": [
        "model = nn.Sequential(\n",
        "    SimpleModel(tok.num_tokens, 16, 32),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "loss = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, mode='max')\n",
        "scheduler2 = torch.optim.lr_scheduler.StepLR(optimizer, 2, 0.1)\n",
        "\n",
        "loss_hist, acc_hist = train_model(model, train_loader, val_loader, 10, optimizer, loss, \n",
        "                                   classification=True, plato_scheduler=scheduler1, scheduler=scheduler2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train loss: 0.6705866456031799\n",
            "Train accuracy: 0.5716\n",
            "Val loss: 0.6306892037391663\n",
            "Val accuracy: 0.6412\n",
            "Epoch 1\n",
            "Train loss: 0.5943325161933899\n",
            "Train accuracy: 0.68505\n",
            "Val loss: 0.5425017476081848\n",
            "Val accuracy: 0.7288\n",
            "Epoch 2\n",
            "Train loss: 0.5280731916427612\n",
            "Train accuracy: 0.74805\n",
            "Val loss: 0.5004121661186218\n",
            "Val accuracy: 0.7672\n",
            "Epoch 3\n",
            "Train loss: 0.47268837690353394\n",
            "Train accuracy: 0.7863\n",
            "Val loss: 0.43972328305244446\n",
            "Val accuracy: 0.8048\n",
            "Epoch 4\n",
            "Train loss: 0.423369824886322\n",
            "Train accuracy: 0.81535\n",
            "Val loss: 0.41856592893600464\n",
            "Val accuracy: 0.8098\n",
            "Epoch 5\n",
            "Train loss: 0.37628108263015747\n",
            "Train accuracy: 0.8396\n",
            "Val loss: 0.38602039217948914\n",
            "Val accuracy: 0.8366\n",
            "Epoch 6\n",
            "Train loss: 0.37803909182548523\n",
            "Train accuracy: 0.8385\n",
            "Val loss: 0.4224628210067749\n",
            "Val accuracy: 0.8228\n",
            "Epoch 7\n",
            "Train loss: 0.33113738894462585\n",
            "Train accuracy: 0.86295\n",
            "Val loss: 0.41826242208480835\n",
            "Val accuracy: 0.8448\n",
            "Epoch 8\n",
            "Train loss: 0.29100584983825684\n",
            "Train accuracy: 0.8794\n",
            "Val loss: 0.3850339651107788\n",
            "Val accuracy: 0.8514\n",
            "Epoch 9\n",
            "Train loss: 0.2653753459453583\n",
            "Train accuracy: 0.89355\n",
            "Val loss: 0.3363730013370514\n",
            "Val accuracy: 0.866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doa7FiVDL79r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "3c9f96c2-ed7f-41b1-b80b-2cd402cce0f9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(10), val_hist)\n",
        "plt.plot(range(10), train_hist)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2889c2ed30>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dMkrCb_JDgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7324a091-9f06-4db0-ba57-f66981ef10d3"
      },
      "source": [
        "import joblib\n",
        "\n",
        "torch.save(model.state_dict(), PATH + 'classification.pt')\n",
        "joblib.dump(tok, PATH + 'tokenizer.joblib')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./tokenizer.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01RYzyRbcjoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "outputId": "0b5f9223-916f-4738-fe18-d81de482d97d"
      },
      "source": [
        "reg_model = model[0].to(device)\n",
        "loss = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, mode='max')\n",
        "\n",
        "train_hist, val_hist = train_model(reg_model, train_loader, val_loader, 10, optimizer, loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train loss: 12.872408866882324\n",
            "Train accuracy: 0.0078\n",
            "Val loss: 11.108055114746094\n",
            "Val accuracy: 0.0294\n",
            "Epoch 1\n",
            "Train loss: 9.667640686035156\n",
            "Train accuracy: 0.08345\n",
            "Val loss: 8.611762046813965\n",
            "Val accuracy: 0.122\n",
            "Epoch 2\n",
            "Train loss: 7.752617835998535\n",
            "Train accuracy: 0.1314\n",
            "Val loss: 7.709372520446777\n",
            "Val accuracy: 0.1452\n",
            "Epoch 3\n",
            "Train loss: 6.0280442237854\n",
            "Train accuracy: 0.1564\n",
            "Val loss: 6.495204925537109\n",
            "Val accuracy: 0.1532\n",
            "Epoch 4\n",
            "Train loss: 4.992058277130127\n",
            "Train accuracy: 0.1738\n",
            "Val loss: 6.6857590675354\n",
            "Val accuracy: 0.1644\n",
            "Epoch 5\n",
            "Train loss: 4.746802806854248\n",
            "Train accuracy: 0.17555\n",
            "Val loss: 6.718478202819824\n",
            "Val accuracy: 0.1514\n",
            "Epoch 6\n",
            "Train loss: 3.9804162979125977\n",
            "Train accuracy: 0.19385\n",
            "Val loss: 6.276157379150391\n",
            "Val accuracy: 0.2086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-373e4cff5e22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-0f780bde98e2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, epochs, optimizer, loss, scheduler)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_acum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi_step\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_quality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0macc_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-0f780bde98e2>\u001b[0m in \u001b[0;36mcompute_quality\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss_acum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e20b5b61f0a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#h = self.batchnorm(h[:, -1, :])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mestimate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 570\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.73 GiB total capacity; 13.92 GiB already allocated; 19.88 MiB free; 13.93 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    }
  ]
}